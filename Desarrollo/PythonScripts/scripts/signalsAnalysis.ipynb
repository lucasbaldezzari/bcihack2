{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de señales registradas durante sesiones de entrenamiento y calibración"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SignalProcessor.Filter import Filter\n",
    "from TrialsHandler.TrialsHandler import TrialsHandler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos un filtro usando la clase Filter\n",
    "fm = 250.\n",
    "filter = Filter(8, 12, 50, 2, fm, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los arhchivos del sujeto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data\\darlia_testing\\eegdata\\sesion2\\sn2_ts0_ct1_r1.npy\"\n",
    "rawEEG = np.load(file)\n",
    "\n",
    "eventosFile = \"data\\darlia_testing\\eegdata\\sesion2\\sn2_ts0_ct1_r1_events.txt\"\n",
    "eventos = pd.read_csv(eventosFile, sep = \",\")\n",
    "\n",
    "channelsName = [\"C3\", \"CZ\", \"C4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawEEG.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el tiempo mínimo y máximo para analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinit = 0.5 #el tiempo de inicio se considera ANTES del cue\n",
    "tmax = 4 #el tiempo máximo debe considerarse entre el cue y el final del trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instanciamos la clase TrialsHandler para extraer los trials, labels, nombre de clases, etc.\n",
    "trialhandler = TrialsHandler(rawEEG, eventos, tinit = tinit, tmax = tmax, reject=None, sample_rate=fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialhandler.eventos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesName, classesLabel = trialhandler.classesName #obtenemos el nombre de las clases y sus labels\n",
    "print(classesName)\n",
    "labels = trialhandler.labels #obtenemos los labels de cada trial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando señal\n",
    "\n",
    "Filtramos la señal en la banda $\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_trials = filter.fit_transform(trialhandler.trials) #extraemos los trials y los filtramos\n",
    "\n",
    "print(mu_trials.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada trial con su clase correspondiente\n",
    "\n",
    "Para este análisis vamos a formar un array de la forma [clase, n_trials, n_channels, n_samples]. Pero es **importante** tener en cuenta que para el entrenamiento de los algoritmos la forma de los datos es [n_trials, n_channels, n_samples]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_x_clase = np.zeros((len(classesName),int(mu_trials.shape[0]/len(classesName)), mu_trials.shape[1], mu_trials.shape[2]))\n",
    "\n",
    "#Por cada label dentro de classNames, filtramos los trials y lo guardamos en la posición correspondiente dentro de trials\n",
    "for label in classesLabel:\n",
    "    trials_x_clase[label-1,:,:,:] = mu_trials[labels == label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trials_x_clase.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficando señal\n",
    "\n",
    "Vamos a graficar la señal para un trial en particular. Además, vamos a marcar la ventana de tiempo en donde la persona realizaba la tarea solicitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_n = 2 #Selecciono el trial que quiero clasificar\n",
    "label = labels[trial_n-1] #Obtengo la etiqueta del trial\n",
    "\n",
    "eventos.index = eventos[\"trialNumber\"]\n",
    "min_tinit = eventos[\"startingTime\"].min()\n",
    "startingTime = eventos.loc[trial_n][\"startingTime\"]\n",
    "cue_duration = eventos.loc[trial_n][\"cueDuration\"]\n",
    "finish_time = eventos.loc[trial_n][\"finishDuration\"]\n",
    "\n",
    "trozo_inicial = startingTime - tinit\n",
    "trozo_final = tmax - cue_duration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eje temporal. El mismo va desde -tinit hasta tmax\n",
    "t = np.arange(-tinit, tmax, 1/250.)\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    plt.plot(t[int(tinit*fm):], trials_x_clase[label-1,trial_n-1, i,int(tinit*fm) :])\n",
    "    #linea vertical en el tiempo de inicio del cue. Linea punteada\n",
    "    plt.axvline(x = 0, color=\"#656ccf\", linestyle=\"--\")\n",
    "    #agrego un rectangulo de color verde con fondo transparente entre el tiempo de inicio del cue y el tiempo del cue\n",
    "    plt.axvspan(0, cue_duration, color=\"#65cf70\", alpha=0.2)\n",
    "    plt.xlabel(\"Tiempo (s)\")\n",
    "    plt.ylabel(\"Amplitud (uV)\")\n",
    "    plt.title(\"Canal {}\".format(channelsName[i]))\n",
    "\n",
    "plt.suptitle(f\"Señal para el trial {trial_n} - Clase {classesName[classesLabel.index(label)]}\")\n",
    "#dismiuimos el espacio entre subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos para trials promediados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_promedio = trials_x_clase.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Grafico tres canales en tres subplots\n",
    "\n",
    "clase = 1\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    plt.plot(t[int(tinit*fm):], trials_promedio[clase-1, i, int(tinit*fm):])\n",
    "    #linea vertical en el tiempo de inicio del cue. Linea punteada\n",
    "    plt.axvline(x = 0, color=\"#656ccf\", linestyle=\"--\")\n",
    "    #agrego un rectangulo de color verde con fondo transparente entre el tiempo de inicio del cue y el tiempo del cue\n",
    "    plt.axvspan(0, cue_duration, color=\"#65cf70\", alpha=0.2)\n",
    "    #cambiamos el color del fondo de toda la figura a gris\n",
    "    plt.xlabel(\"Tiempo (s)\")\n",
    "    plt.ylabel(\"Amplitud (uV)\")\n",
    "    plt.title(\"Canal {}\".format(channelsName[i]))\n",
    "\n",
    "plt.suptitle(f\"Promedio sobre {trial_n} - Clase {classesName[classesLabel.index(clase)]}\")\n",
    "#dismiuimos el espacio entre subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrayendo características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SignalProcessor.FeatureExtractor import FeatureExtractor\n",
    "fe_welch = FeatureExtractor(method=\"welch\", sample_rate=250., axisToCompute = 3) #instanciamos el extractor de características"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que _axisToCompute = 3_ ya que los datos vienen de la forma [clase, n_trials, n_channels, n_samples]. Lo habitual es _axisToCompute = 2_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_x_clase_welch = fe_welch.fit_transform(trials_x_clase)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos las características para cada una de las clases y para un trial en particular.\n",
    "\n",
    "Además, sólo vamos a graficar las frecuencias entre los $5Hz$ y los $28Hz$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 2\n",
    "freq_indexes = np.where((fe_welch.freqs >= 5) & (fe_welch.freqs <= 20))[0] #obtenemos los índices de las frecuencias entre 5 y 18 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#1e81b0\", \"#c13f48\", \"#65cf70\", \"#f5b041\", \"#5d6d7e\"]\n",
    "\n",
    "fig, axs = plt.subplots(len(channelsName), 1, figsize=(8, 7), sharex=True, sharey=True)\n",
    "for i, channel in enumerate(channelsName):\n",
    "    for j, clase in enumerate(classesName):\n",
    "        axs[i].plot(fe_welch.freqs[freq_indexes], trials_x_clase_welch[j,trial - 1, i, :][freq_indexes], label=clase, linewidth=2, color = colors[j])\n",
    "        #creamos un rectángulo para resaltar la banda mu\n",
    "    axs[i].axvspan(8, 12, alpha=0.1, color='grey')\n",
    "    axs[i].set_title(channel)\n",
    "    axs[i].set_ylabel('Potencia (dB)')\n",
    "    axs[i].set_xlabel('Frecuencia (Hz)')\n",
    "    axs[i].legend()\n",
    "\n",
    "#reduzco el padding entre subplots\n",
    "plt.suptitle(f'EEG en la banda $mu$ para trial {trial} - Todas las clases')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a graficar las características pero sólo para dos clases. De esta manera, podemos comparar mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 1\n",
    "clase1 = 1\n",
    "clase2 = 2\n",
    "\n",
    "fig, axs = plt.subplots(len(channelsName), 1, figsize=(8, 7), sharex=True, sharey=True)\n",
    "for i, channel in enumerate(channelsName):\n",
    "    axs[i].plot(fe_welch.freqs[freq_indexes], trials_x_clase_welch[clase1-1, trial - 1, i, :][freq_indexes], linewidth=2, color = \"#1e81b0\")\n",
    "    axs[i].plot(fe_welch.freqs[freq_indexes], trials_x_clase_welch[clase2-1, trial - 1, i, :][freq_indexes], linewidth=2, color = \"#c13f48\")\n",
    "    #creamos un rectángulo para resaltar la banda mu\n",
    "    axs[i].axvspan(8, 12, alpha=0.1, color='grey')\n",
    "    axs[i].set_title(channel)\n",
    "    axs[i].set_ylabel('Potencia (dB)')\n",
    "    axs[i].set_xlabel('Frecuencia (Hz)')\n",
    "    axs[i].legend([classesName[clase1-1], classesName[clase2-1]])\n",
    "\n",
    "#reduzco el padding entre subplots\n",
    "plt.suptitle(f'EEG en la banda $mu$ para trial {trial} - Clases {classesName[clase1-1]} y {classesName[clase2-1]}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando CSP a los datos\n",
    "\n",
    "Ahora vamos a aplicar CSP a nuestros datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la clase _CSPMulticlass_ e instanciamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SignalProcessor.CSPMulticlass import CSPMulticlass\n",
    "cspmulticlass = CSPMulticlass(n_components=2, method = \"ovo\", n_classes = len(np.unique(labels)), reg = 0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separamos en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "#separamos en train y test. Balanceamos las clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(mu_trials, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos los filtros espaciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamos el CSP\n",
    "cspmulticlass.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el CSP a los trials para ver si mejora la separación entre clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aplico CSP a mu_trials\n",
    "mu_trials_csp = cspmulticlass.transform(mu_trials)\n",
    "print(mu_trials_csp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_welch = FeatureExtractor(method=\"welch\", sample_rate=250., axisToCompute = 2, band_values=[5,18]) #instanciamos el extractor de características\n",
    "mu_trials_csp_welch = fe_welch.fit_transform(mu_trials_csp)\n",
    "print(mu_trials_csp_welch.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unificando componentes\n",
    "\n",
    "Vamos a unificar cada componente obtenida desde el CSP en una sóla. De esta manera, podemos analizar cómo se distribuyen las características para cada clase y así podemos compararlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SignalProcessor.RavelTransformer import RavelTransformer\n",
    "raveltransformer = RavelTransformer() #instanciamos el raveltransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_trials_csp_welch_ravel = raveltransformer.fit_transform(mu_trials_csp_welch)\n",
    "print(mu_trials_csp_welch_ravel.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a graficar algunas de las características que hemos obtenido para la clase Mano Izquierda (label = 1) y clase Mano Derecha (label = 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reordenamos los trials para que queden en la forma [clase, n_trials, n_features]. Usamos labels para reordenar\n",
    "\n",
    "trials_csp_welch_ravel = np.zeros((len(classesName),int(mu_trials_csp_welch_ravel.shape[0]/len(classesName)), mu_trials_csp_welch_ravel.shape[1]))\n",
    "\n",
    "#Por cada label dentro de classNames, filtramos los trials y lo guardamos en la posición correspondiente dentro de trials\n",
    "for label in classesLabel:\n",
    "    trials_csp_welch_ravel[label-1,:,:] = mu_trials_csp_welch_ravel[labels == label]\n",
    "\n",
    "print(trials_csp_welch_ravel.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formamos un array con el trial uno de cada clase\n",
    "trial = 1\n",
    "trial1_clases = trials_csp_welch_ravel[:,trial-1,:]\n",
    "print(trial1_clases.shape) \n",
    "\n",
    "## Contacatenamos los trials de cada clase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 2\n",
    "clase1 = 1\n",
    "clase2 = 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(trials_csp_welch_ravel[clase1-1, trial - 1, :], linewidth=2, color = \"#1e81b0\", label = classesName[clase1-1])\n",
    "ax.plot(trials_csp_welch_ravel[clase2-1, trial - 1, :], linewidth=2, color = \"#c13f48\", label = classesName[clase2-1])\n",
    "ax.set_ylabel('Potencia (dB)')\n",
    "ax.set_xlabel('Frecuencia (Hz)')\n",
    "ax.legend()\n",
    "plt.title(f'EEG en la banda $mu$ para trial {trial} - Clases {classesName[clase1-1]} y {classesName[clase2-1]}')\n",
    "plt.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de la figura anterior\n",
    "\n",
    "Entendiendo que _CSPMulticlass_ al ser entrenada con el parámetro _ovo_ es decir _one vs one_, estaremos entrenando un total de $ n_{filters} = \\frac{n_{clases}\\times(n_{clases})}{2}$, luego si $n_{clases} = 5$ tendremos $n_{filters} = 10$. Luego, si la cantidad de componentes seleccionada es $2$ la clase _CSPMulticlass_ nos retornará un total de $2\\times10 = 20$ componentes, es decir, dos componentes por cada filtro entrenado.\n",
    "\n",
    "Por lo tanto, por cada señal de entrada a `CSPMulticlass.transform()` de la forma _[n_trials, n_channels, n_samples]_ obtendremos una salida equivalente a _[n_trials, n_components, n_samples]_.\n",
    "\n",
    "Luego cuando extraemos las características, estamos extrayendo las componentes frecuenciales de cada componente de EEG habiendo sido proyectado al nuevo espaco. Finalmente y para poder luego usar las características en un clasificador, es que unificamos (usando _Ravel_) en una sóla componente cada una de las componentes obtenidas.\n",
    "\n",
    "Podemos ver que las características entre las clases Mano Izquierda y Mano Derecha son diferentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando _pipeline()_ para clasificar la señal\n",
    "\n",
    "Vamos a utilizar el método _Pipeline_ de Skit-Learn para generar un pipeline que tome la señal de EEG cruda, la filtre, obtenga los filtros aplicando CSPMulticlass, realice la extracción de características con FeatureExtractor, aplique el RavelTransformer y clasifique con un LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrialsHandler.TrialsHandler import TrialsHandler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han extraido 25 trials\n",
      "Se han extraido 3 canales\n",
      "Se han extraido 1125 muestras por trial\n",
      "['Mano Izquierda', 'Mano Derecha', 'Ambas Manos', 'Pies', 'Rest']\n"
     ]
    }
   ],
   "source": [
    "fm = 250.\n",
    "file = \"data\\pablo_testing\\eegdata\\sesion1\\sn1_ts0_ct1_r2.npy\"\n",
    "rawEEG = np.load(file)\n",
    "\n",
    "eventosFile = \"data\\pablo_testing\\eegdata\\sesion1\\sn1_ts0_ct1_r2_events.txt\"\n",
    "eventos = pd.read_csv(eventosFile, sep = \",\")\n",
    "\n",
    "channelsName = [\"C3\", \"CZ\", \"C4\"]\n",
    "tinit = 0.5 #el tiempo de inicio se considera ANTES del cue\n",
    "tmax = 4 #el tiempo máximo debe considerarse entre el cue y el final del trial\n",
    "## Instanciamos la clase TrialsHandler para extraer los trials, labels, nombre de clases, etc.\n",
    "trialhandler = TrialsHandler(rawEEG, eventos, tinit = tinit, tmax = tmax, reject=None, sample_rate=fm)\n",
    "\n",
    "classesName, classesLabel = trialhandler.classesName #obtenemos el nombre de las clases y sus labels\n",
    "print(classesName)\n",
    "labels = trialhandler.labels #obtenemos los labels de cada trial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciamos las clases a utilizar en el Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SignalProcessor.Filter import Filter\n",
    "from SignalProcessor.FeatureExtractor import FeatureExtractor\n",
    "from SignalProcessor.CSPMulticlass import CSPMulticlass\n",
    "from SignalProcessor.RavelTransformer import RavelTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = Filter(lowcut=8, highcut=12, notch_freq=50.0, notch_width=2, sample_rate=fm, axisToCompute=2, padlen=None, order=4)\n",
    "#Creamos un CSPMulticlass - Método ovo (one vs one)\n",
    "cspmulticlass = CSPMulticlass(n_components=2, method = \"ova\", n_classes = len(np.unique(labels)), reg = 0.01)\n",
    "featureExtractor = FeatureExtractor(method = \"welch\", sample_rate = fm, axisToCompute=2, band_values=[5,18])\n",
    "ravelTransformer = RavelTransformer()\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA() #instanciamos el clasificador LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a probar un LDA\n",
    "pipeline_lda = Pipeline([\n",
    "    ('pasabanda', filter),\n",
    "    ('cspmulticlase', cspmulticlass),\n",
    "    ('featureExtractor', featureExtractor),\n",
    "    ('ravelTransformer', ravelTransformer),\n",
    "    ('lda', lda)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3, 1125)\n"
     ]
    }
   ],
   "source": [
    "trials_raw = trialhandler.trials\n",
    "print(trials_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dividimos raw_eeg en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "#separamos en train y test. Balanceamos las clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(trials_raw, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.38 (2.2e-16 eps * 3 dim * 5.8e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.91 (2.2e-16 eps * 3 dim * 1.4e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.2 (2.2e-16 eps * 3 dim * 3e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.96 (2.2e-16 eps * 3 dim * 1.4e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.51 (2.2e-16 eps * 3 dim * 7.6e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.84 (2.2e-16 eps * 3 dim * 1.3e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.55 (2.2e-16 eps * 3 dim * 8.2e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.82 (2.2e-16 eps * 3 dim * 1.2e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.48 (2.2e-16 eps * 3 dim * 7.1e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.86 (2.2e-16 eps * 3 dim * 1.3e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pasabanda&#x27;, Filter(highcut=12, lowcut=8, notch_width=2)),\n",
       "                (&#x27;cspmulticlase&#x27;, CSPMulticlass(method=&#x27;ova&#x27;, reg=0.01)),\n",
       "                (&#x27;featureExtractor&#x27;, FeatureExtractor(band_values=[5, 18])),\n",
       "                (&#x27;ravelTransformer&#x27;, RavelTransformer()),\n",
       "                (&#x27;lda&#x27;, LinearDiscriminantAnalysis())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pasabanda&#x27;, Filter(highcut=12, lowcut=8, notch_width=2)),\n",
       "                (&#x27;cspmulticlase&#x27;, CSPMulticlass(method=&#x27;ova&#x27;, reg=0.01)),\n",
       "                (&#x27;featureExtractor&#x27;, FeatureExtractor(band_values=[5, 18])),\n",
       "                (&#x27;ravelTransformer&#x27;, RavelTransformer()),\n",
       "                (&#x27;lda&#x27;, LinearDiscriminantAnalysis())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Filter</label><div class=\"sk-toggleable__content\"><pre>Filter(highcut=12, lowcut=8, notch_width=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CSPMulticlass</label><div class=\"sk-toggleable__content\"><pre>CSPMulticlass(method=&#x27;ova&#x27;, reg=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>FeatureExtractor(band_values=[5, 18])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RavelTransformer</label><div class=\"sk-toggleable__content\"><pre>RavelTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pasabanda', Filter(highcut=12, lowcut=8, notch_width=2)),\n",
       "                ('cspmulticlase', CSPMulticlass(method='ova', reg=0.01)),\n",
       "                ('featureExtractor', FeatureExtractor(band_values=[5, 18])),\n",
       "                ('ravelTransformer', RavelTransformer()),\n",
       "                ('lda', LinearDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Entrenamos el pipeline_lda\n",
    "\n",
    "pipeline_lda.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usamos pipeline_lda\n",
    "\n",
    "Ahora vamos a usar _pipeline_lda_ para clasificar los datos de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accu: 80.0%\n"
     ]
    }
   ],
   "source": [
    "## Ahora vamos a usar _pipeline_lda_ para clasificar los datos de testeo\n",
    "\n",
    "y_pred = pipeline_lda.predict(X_test)\n",
    "\n",
    "## Calculamos la accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"Accu: {accuracy_score(y_test, y_pred)*100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generamos un Pipeline para clasificar con un clasificador SVM\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=0.1, probability=True) #instanciamos el clasificador SVM\n",
    "\n",
    "#Vamos a probar un LDA\n",
    "pipeline_svm = Pipeline([\n",
    "    ('pasabanda', filter),\n",
    "    ('cspmulticlase', cspmulticlass),\n",
    "    ('featureExtractor', featureExtractor),\n",
    "    ('ravelTransformer', ravelTransformer),\n",
    "    ('svm', svm)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.38 (2.2e-16 eps * 3 dim * 5.8e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.91 (2.2e-16 eps * 3 dim * 1.4e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.2 (2.2e-16 eps * 3 dim * 3e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.96 (2.2e-16 eps * 3 dim * 1.4e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.51 (2.2e-16 eps * 3 dim * 7.6e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.84 (2.2e-16 eps * 3 dim * 1.3e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.55 (2.2e-16 eps * 3 dim * 8.2e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.82 (2.2e-16 eps * 3 dim * 1.2e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.48 (2.2e-16 eps * 3 dim * 7.1e+14  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.86 (2.2e-16 eps * 3 dim * 1.3e+15  max singular value)\n",
      "    Estimated rank (mag): 3\n",
      "    MAG: rank 3 computed from 3 data channels with 0 projectors\n",
      "Reducing data rank from 3 -> 3\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pasabanda&#x27;, Filter(highcut=12, lowcut=8, notch_width=2)),\n",
       "                (&#x27;cspmulticlase&#x27;, CSPMulticlass(method=&#x27;ova&#x27;, reg=0.01)),\n",
       "                (&#x27;featureExtractor&#x27;, FeatureExtractor(band_values=[5, 18])),\n",
       "                (&#x27;ravelTransformer&#x27;, RavelTransformer()),\n",
       "                (&#x27;svm&#x27;, SVC(C=0.1, kernel=&#x27;linear&#x27;, probability=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pasabanda&#x27;, Filter(highcut=12, lowcut=8, notch_width=2)),\n",
       "                (&#x27;cspmulticlase&#x27;, CSPMulticlass(method=&#x27;ova&#x27;, reg=0.01)),\n",
       "                (&#x27;featureExtractor&#x27;, FeatureExtractor(band_values=[5, 18])),\n",
       "                (&#x27;ravelTransformer&#x27;, RavelTransformer()),\n",
       "                (&#x27;svm&#x27;, SVC(C=0.1, kernel=&#x27;linear&#x27;, probability=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Filter</label><div class=\"sk-toggleable__content\"><pre>Filter(highcut=12, lowcut=8, notch_width=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CSPMulticlass</label><div class=\"sk-toggleable__content\"><pre>CSPMulticlass(method=&#x27;ova&#x27;, reg=0.01)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>FeatureExtractor(band_values=[5, 18])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RavelTransformer</label><div class=\"sk-toggleable__content\"><pre>RavelTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pasabanda', Filter(highcut=12, lowcut=8, notch_width=2)),\n",
       "                ('cspmulticlase', CSPMulticlass(method='ova', reg=0.01)),\n",
       "                ('featureExtractor', FeatureExtractor(band_values=[5, 18])),\n",
       "                ('ravelTransformer', RavelTransformer()),\n",
       "                ('svm', SVC(C=0.1, kernel='linear', probability=True))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Entrenamos el pipeline_svm\n",
    "pipeline_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ahora vamos a usar _pipeline_svm_ para clasificar los datos de testeo\n",
    "y_pred = pipeline_svm.predict(X_test)\n",
    "\n",
    "## Calculamos la accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcihack2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "427bc2f4f183b4d59cc335d04a148e47d162e279da39c42df44c0b5060f1c179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
