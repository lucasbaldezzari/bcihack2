{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed4de2a",
   "metadata": {},
   "source": [
    "# <center><span style='color:#229954'>Taller 2 - Introducci√≥n al *Machine Learning*</span><center>\n",
    "\n",
    "Ejemplos para presentaci√≥n del taller n√∫mero 2.\n",
    "\n",
    "Hackathon ICC 2022/2023.\n",
    "\n",
    "*Autor*: MSc. Bioing. BALDEZZARI Lucas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c66699",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importamos m√≥dulos\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b127e",
   "metadata": {},
   "source": [
    "## <span style='color:#3c3b5f'>Supervised Learning</span>\n",
    "\n",
    "El aprendizaje supervisado se basa en entrenar modelos que aprenden de datos que poseen etiquetas. Luego, los modelos se utilizan para etiquetar datos desconocidos.\n",
    "\n",
    "### Clasificaci√≥n: Prediciendo *labels* discretas\n",
    "\n",
    "A continuaci√≥n realizaremos un ejemplo sencillo de clasificaci√≥n utilizando un modelo llamado *Support Vector Machine*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generamos algunos puntos en dos dimensiones\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "## creamos 100 puntos separables\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=2, cluster_std=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d66ba",
   "metadata": {},
   "source": [
    "Analicemos brevemente que tenemos en $X$ y que en $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:10])\n",
    "print()\n",
    "print(\"Etiquetas\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8983cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "estiloPuntos = dict(cmap='RdYlGn', s=45)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **estiloPuntos)\n",
    "ax.axis([-4, 4, -12, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac26841",
   "metadata": {},
   "source": [
    "Primero importamos el modelo SVS de scikit-learn, el mismo corresponde a [sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35cb5f6",
   "metadata": {},
   "source": [
    "Ahora creamos el modelo y lo entrenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el modelo y le pasamos los datos de entrada y sus correspondientes etiquetas.\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X, y) #entrenamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac04a30",
   "metadata": {},
   "source": [
    "Veamos que tan bien separa los datos el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03413ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(-4, 5, 15)\n",
    "yy = np.linspace(-12, 2, 15)\n",
    "xy1, xy2 = np.meshgrid(xx, yy)\n",
    "Z = np.array([svc.decision_function([t])\n",
    "              for t in zip(xy1.flat, xy2.flat)]).reshape(xy1.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "estiloLineas = dict(levels = [-1.0, 0.0, 1.0],\n",
    "                  linestyles = ['dashed', 'solid', 'dashed'],\n",
    "                  colors = 'blue', linewidths=1)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"SVC entrenado a partir de los datos\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **estiloPuntos)\n",
    "ax.contour(xy1, xy2, Z, **estiloLineas)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882dd0d3",
   "metadata": {},
   "source": [
    "Veamos que tan bien funciona nuestro modelo para predecir nuevos puntos.\n",
    "\n",
    "Para esto generaremos puntos nuevos y usaremos el modelo *svc* entrenado para predecir a qu√© clase pertenecen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d040af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, _ = make_blobs(n_samples=100, centers=2, random_state=2, cluster_std=0.95)\n",
    "X2 = X2[50:]\n",
    "\n",
    "# Predecimos a que clase (etiqueta) pertenecen nuestros puntos utilizando el modelo entrenado\n",
    "y2 = svc.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217324d5",
   "metadata": {},
   "source": [
    "Ahora graficaremos los datos nuevos sin clasificaci√≥n y luego habiendo sido clasificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b645289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols = 2, figsize = (14,6))\n",
    "\n",
    "ax[0].set_xlabel(\"Feature 1\")\n",
    "ax[0].set_ylabel(\"Feature 2\")\n",
    "ax[0].set_title(\"Datos de entrada nuevos (y desconocidos)\")\n",
    "ax[0].scatter(X2[:, 0], X2[:, 1])\n",
    "ax[0].axis([-4, 4, -12, 2])\n",
    "\n",
    "ax[1].set_xlabel(\"Feature 1\")\n",
    "ax[1].set_ylabel(\"Feature 2\")\n",
    "ax[1].set_title(\"Datos nuevos clasificados\")\n",
    "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, **estiloPuntos)\n",
    "ax[1].contour(xy1, xy2, Z, **estiloLineas)\n",
    "ax[1].axis([-4, 4, -12, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072b541",
   "metadata": {},
   "source": [
    "### Ejemplo de Regresi√≥n\n",
    "\n",
    "Ahora vamosa generar un sencillo ejemplo de regresi√≥n lineal para clasificar datos continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generamos datos \n",
    "rng = np.random.RandomState(10)\n",
    "X = rng.randn(200, 2) #posici√≥n de los puntos en el espacio\n",
    "y = np.dot(X, [-2, 1]) + 1 * rng.randn(X.shape[0]) #etiquetas de los puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los puntos.\n",
    "plt.style.use(\"seaborn\")\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap='winter')\n",
    "\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "\n",
    "ax.axis([-3, 3, -4, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Posici√≥n de los puntos\")\n",
    "print(X[:10])\n",
    "print()\n",
    "print(\"Etiquetas\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25906fd",
   "metadata": {},
   "source": [
    "Cada color representa una etiqueta diferente para cada punto.\n",
    "\n",
    "Podr√≠amos pensar tambi√©n en que cada punto tiene una *altura* diferente y dicha altura se corresponde con la etiqueta. Esto lo podemos representar en un gr√°fico de tres dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841eaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = np.hstack([X, y[:, None]])\n",
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e3c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(datos[:,0], datos[:,1], datos[:,2],c=y, s=40, cmap='winter')\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_zlabel(\"Labels\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "\n",
    "# ax.view_init(-10, -120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4dcd6",
   "metadata": {},
   "source": [
    "#### Etiquetando datos\n",
    "\n",
    "A partir de analizar los datos en 3D podemos pensar que un plano ayudar√≠a a separar los puntos. Una forma de hacer esto es entrenando un [Regresor Lineal](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9066472",
   "metadata": {},
   "source": [
    "Podemos proyectar los datos 3D en 2D con el plano obtenido luego de entrenar el regresor lineal con los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pts = ax.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap='winter', zorder=2)\n",
    "\n",
    "# compute and plot model color mesh\n",
    "xx, yy = np.meshgrid(np.linspace(-4, 4),np.linspace(-3, 3))\n",
    "Xfit = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "yfit = lr.predict(Xfit)\n",
    "zz = yfit.reshape(xx.shape)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada con el regresor lineal\")\n",
    "ax.pcolorfast([-4, 4], [-4, 4], zz, alpha=0.5, cmap='winter', norm=pts.norm, zorder=1)\n",
    "\n",
    "ax.axis([-3, 3, -4, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8483a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creamos nuevos datos\n",
    "X2 = rng.randn(100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtenemos las etiquetas para estos nuevos datos a trav√©s del modelo entrenado\n",
    "\n",
    "y2 = lr.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los nuevos datos.\n",
    "plt.style.use(\"seaborn\")\n",
    "fig, ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].set_xlabel(\"Feature 1\")\n",
    "ax[0].set_ylabel(\"Feature 2\")\n",
    "ax[0].set_title(\"Datos desconocidos\")\n",
    "ax[0].axis([-3, 3, -4, 4])\n",
    "ax[0].scatter(X2[:, 0], X2[:, 1])\n",
    "\n",
    "ax[1].set_xlabel(\"Feature 1\")\n",
    "ax[1].set_ylabel(\"Feature 2\")\n",
    "ax[1].set_title(\"Etiquetas para los nuevos datos usando el Regresor Lineal\")\n",
    "ax[1].axis([-3, 3, -4, 4])\n",
    "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=40, cmap='winter')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82357152",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "Hemos visto dos sencillos modelos de aprendizaje supervisado. Los mismos aprenden de datos etiquetados y una vez entrenados, sirven para etiquetar datos nuevos.\n",
    "\n",
    "En el caso del aprendizaje no supervisado, el modelo *aprende* sin ninguna referencia a una etiqueta.\n",
    "\n",
    "### Ejemplo de Clustering\n",
    "\n",
    "Un m√©todo muy conocido de aprendizaje no supervisado es *Clustering*, en donde los datos son asignados a un n√∫mero *n* de grupos discretos.\n",
    "\n",
    "Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# creamos 100 puntos separados con cuatro centros. S√≥lo nos quedamos con las posiciones.\n",
    "X, _ = make_blobs(n_samples = 100, centers = 4, random_state = 20, cluster_std=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "ax.scatter(X[:, 0], X[:, 1])\n",
    "ax.axis([-15, 12, -5, 13])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9af1a",
   "metadata": {},
   "source": [
    "#### Kmeans\n",
    "\n",
    "Utilizaremos el algoritmo de Kmeans para separar en grupos los datos de entrada que hemos generado. Sikit-learn provee su propio m√©todo dado por [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters = 4, random_state=0) #le decimos que queremos que nos separe en 4 grupos\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debabcf5",
   "metadata": {},
   "source": [
    "Utilizamos el modelo entrenado para obtener los grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fa6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "estiloPuntos = dict(cmap='magma_r', s=45)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada agrupados con Kmeans\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **estiloPuntos)\n",
    "ax.axis([-15, 12, -5, 13])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d351c7",
   "metadata": {},
   "source": [
    "**Importante**: Debemos tener en claro que los grupos se obtuvieron a partir del algortimo, es decir, que *Kmeans()* nos permiti√≥ agrupar los datos y luego los etiquetamos, esto puede verse gracias a los colores diferentes que toman los puntos, donde cada color representa un grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b6651",
   "metadata": {},
   "source": [
    "### Reduciendo la dimensiones de mis datos\n",
    "\n",
    "En muchos casos, los datos son ùëÅ-dimensionales, con ùëÅ>3. Podr√≠a ser √∫til reducir la dimensi√≥n de nuestros datos, para analizarlos, para procesarlos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "# make data\n",
    "X, y = make_swiss_roll(200, noise=0.5, random_state=42)\n",
    "X = X[:, [0, 2]]\n",
    "\n",
    "# visualize data\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos originales\")\n",
    "ax.scatter(X[:, 0], X[:, 1], s=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176d4fe4",
   "metadata": {},
   "source": [
    "#### Algoritmos del tipo *Manifold*\n",
    "\n",
    "Podemos usar un algoritmo conocido como [Isometric Mapping](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py) para reducir la dimensi√≥n de nuestros datos. En escencia lo que intenta hacer el algoritmo es extraer informaci√≥n para representar los datos en dimensiones bajas, y al mismo tiempo, preservar las caracter√≠sticas relevantes del conjunto de datos, el cual se supone posee una estructura compleja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "isomap = Isomap(n_neighbors=8, n_components=1)\n",
    "y_Obtenidos = isomap.fit_transform(X).ravel()\n",
    "\n",
    "# visualize data\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Variaci√≥n de datos aprendido por Isomap\")\n",
    "pts = ax.scatter(X[:, 0], X[:, 1], c=y_Obtenidos, cmap='winter', s=30)\n",
    "cb = fig.colorbar(pts, ax=ax)\n",
    "cb.set_ticks([])\n",
    "cb.set_label('Variaci√≥n latente', color='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d3b1d",
   "metadata": {},
   "source": [
    "## Introducci√≥n a *Scikit-Learn*\n",
    "\n",
    "Sabemos que el ML trata de entrenar modelos a partir de datos para hacer algo con ellos.\n",
    "\n",
    "Ahora bien, ¬øqu√© estructura deben de tener los datos para poder entrenar algoritmos?\n",
    "\n",
    "**Datos como tablas**\n",
    "\n",
    "La forma b√°sica es trabajar los datos como tablas.\n",
    "\n",
    "Las columnas representan las caracter√≠sticas y las filas las observaciones.\n",
    "\n",
    "Veamos un ejemplo con un set muy conocido, el cual se llama *Iris dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542250fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d9de2",
   "metadata": {},
   "source": [
    "Si tomamos a la columna *species* como el *vector de blancos* entonces podemos ver que nuestros datos poseen una matr√≠z de caracter√≠sticas con un tama√±o de $150 x 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6a9d6",
   "metadata": {},
   "source": [
    "#### Pasos b√°sicos para la implementaci√≥n de un modelo.\n",
    "\n",
    "1. Elegir un modelo adecuado al problema que queremos resolver/analizar.\n",
    "2. Elegir los hiperpar√°metros del modelo instanciando esta clase con los valores deseados\n",
    "3. Organizar los datos en una matriz de caracter√≠sticas y un vector blanco/target de la forma vista anteriormente.\n",
    "4. Entrenar el modelo invocando al m√©todo fit().\n",
    "5. Aplicar el modelo a nuevos datos:\n",
    "    - Para aprendizaje supervisado, a menudo predecimos etiquetas para datos desconocidos usando el m√©todo de prediction().\n",
    "    - Para aprendizaje no supervisado, a menudo transformamos o inferimos propiedades de los datos utilizando el m√©todo transform() o predict().\n",
    "\n",
    "Veamos un ejemplo‚Ä¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5a6dc",
   "metadata": {},
   "source": [
    "### Clasificando d√≠gitos escritos a mano\n",
    "\n",
    "Vamos a intentar clasificar n√∫meros que han sido escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28893ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5006cb7f",
   "metadata": {},
   "source": [
    "Podemos ver tenemos 1797 d√≠gitos de $8x8$.\n",
    "\n",
    "Vamos a graficar algunos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50022a5d",
   "metadata": {},
   "source": [
    "#### Construyendo los datos en *matriz de caracter√≠sticas* y *target vector*\n",
    "\n",
    "Primeramente debemos arreglar los datos de tal manera de poder entrenar modelos con Scikit-learn. Para esto necesitamos una tabla de dos dimensiones del tipo [$n_samples$ x $n_features$].\n",
    "\n",
    "Debemos notar que cada d√≠gito es una matriz de 8x8 pix√©les. Por lo tanto, podemos formar vectores filas de 64 p√≠xeles y acomodarlos de tal manera de que formen una matriz de *1797 x 64*.\n",
    "\n",
    "Adem√°s tambi√©n necesitamos un *target vector*. Estos datos los podemos obtener directamente de *digits = load_digits()*, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71885d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data #Matriz de Caracter√≠sticas\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd86cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d92888",
   "metadata": {},
   "source": [
    "Ya tenemos los datos en la forma necesaria para ser utilizados con Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b9a06e",
   "metadata": {},
   "source": [
    "#### Separando en datos de entrenamiento y de testeo\n",
    "\n",
    "Antes que nada, es **de suma importancia** separar los datos en un set de entrenamiento y en otro de testeo. Volveremos sobre esto m√°s adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d0d94",
   "metadata": {},
   "source": [
    "#### Visualizando nuestros datos de entrenamiento.\n",
    "\n",
    "Esta claro que tenemos datos que son dif√≠ciles de interpretar debido a que se encuentran en un espacio de 64 dimensiones. Por lo tanto, aplicaremos la estrategia de *reducci√≥n de dimensionalidad*, es decir, una estrategia de *aprendizaje no supervisado* para intentar analizar los datos que tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec91ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "isomap = Isomap(n_components=2)\n",
    "isomap.fit(Xtrain)\n",
    "datosProyectados = isomap.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "datosProyectados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(datosProyectados[:, 0], datosProyectados[:, 1], c=ytrain, edgecolor='none', alpha=0.4,\n",
    "            cmap=plt.cm.get_cmap('jet', 10))\n",
    "\n",
    "plt.title(\"Isomap de los d√≠gitos - Reducido de 64 a 2 dimensiones\")\n",
    "plt.colorbar(label='label de los d√≠gitos', ticks=range(10))\n",
    "plt.clim(-0.5, 9.5);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54bb00",
   "metadata": {},
   "source": [
    "La gr√°fica de isomap nos da una buena idea de que tan bien los n√∫meros escritos a mano se encuentran separados en el espacio de 64 dimensiones. Por ejemplo, los ceros y los unos pareciera ser que pueden separarse facilmente, al igual que los d√≠gitos cuatro. Esto tiene sentido, por ejemplo, los ceros poseen un hueco en el medio, mientras que los unos son un *palo* en el centro de la im√°gen.\n",
    "\n",
    "En el caso de los dos y los siete, parecen solaparse. Una vez m√°s, intuitivamente esto tiene sentido, un dos y un siete tienen cierta similitud a la hora de dibujarse.\n",
    "\n",
    "Podr√≠amos decir que los datos est√°n m√°s o menos bien separados, ¬øo no? Intentemos clasificar los n√∫meros a partir de los datos reducidos en dimensiones.\n",
    "\n",
    "Utilizaremos el clasificador llamado [sklearn.naive_bayes.GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d98178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # 1. elegimos el clasificador\n",
    "model = GaussianNB()                       # 2. y 3. instanciamos el modelo\n",
    "model.fit(Xtrain, ytrain)                  # 4. entrenamos el modelo con el m√©todo fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9675adae",
   "metadata": {},
   "source": [
    "Debemos notar que hemos entrenado el modelo con los datos de entrenamiento *Xtrain* y las etiquetas de entrenamiento, es decir, *ytrain*.\n",
    "\n",
    "Ahora vamos a clasificar los datos de *Xtest* para etiquetas datos **desconocidos** por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yModelo = model.predict(Xtest)             # 5. clasificamos sobre los datos de testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60723d",
   "metadata": {},
   "source": [
    "Ahora vamos a medir la *performance* del modelo. Para esto vamos a comparar las etiquetas de testeo *ytest* versus las obtenidas *yModelo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "round(accuracy_score(ytest, yModelo),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733de1df",
   "metadata": {},
   "source": [
    "Un 83% de precisi√≥n en la clasificaci√≥n no esta nada mal para un procedimiento sumamente sencillo. Hemos entrenado un modelo y clasificado nuevos datos en muy pocas l√≠neas de c√≥digo.\n",
    "\n",
    "Podemos utilizar una matriz de confusi√≥n para ver r√°pidamente la performance de nuestro clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e33ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(ytest, yModelo)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Valores clasificados')\n",
    "plt.ylabel('Valores verdaderos');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f16d0",
   "metadata": {},
   "source": [
    "Analicemos qu√© n√∫meros fueron los que se clasificaron incorrectamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "imagenesTest = Xtest.reshape(-1, 8, 8)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(imagenesTest[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(yModelo[i]),\n",
    "            transform=ax.transAxes, color='green' if (ytest[i] == yModelo[i]) else 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53169fa0",
   "metadata": {},
   "source": [
    "# <center> <span style='color:#3c3b5f'>FIN</span></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pda]",
   "language": "python",
   "name": "conda-env-pda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
