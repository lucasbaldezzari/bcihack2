{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed4de2a",
   "metadata": {},
   "source": [
    "# <center><span style='color:#229954'>Taller 2 - Introducción al *Machine Learning*</span><center>\n",
    "\n",
    "Ejemplos para presentación del taller número 2.\n",
    "\n",
    "Hackathon ICC 2022/2023.\n",
    "\n",
    "*Autor*: MSc. Bioing. BALDEZZARI Lucas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c66699",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importamos módulos\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b127e",
   "metadata": {},
   "source": [
    "## <span style='color:#3c3b5f'>Supervised Learning</span>\n",
    "\n",
    "El aprendizaje supervisado se basa en entrenar modelos que aprenden de datos que poseen etiquetas. Luego, los modelos se utilizan para etiquetar datos desconocidos.\n",
    "\n",
    "### Clasificación: Prediciendo *labels* discretas\n",
    "\n",
    "A continuación realizaremos un ejemplo sencillo de clasificación utilizando un modelo llamado *Support Vector Machine*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generamos algunos puntos en dos dimensiones\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "## creamos 100 puntos separables\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=2, cluster_std=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d66ba",
   "metadata": {},
   "source": [
    "Analicemos brevemente que tenemos en $X$ y que en $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:10])\n",
    "print()\n",
    "print(\"Etiquetas\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8983cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "estiloPuntos = dict(cmap='RdYlGn', s=45)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **estiloPuntos)\n",
    "ax.axis([-4, 4, -12, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac26841",
   "metadata": {},
   "source": [
    "Primero importamos el modelo SVS de scikit-learn, el mismo corresponde a [sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35cb5f6",
   "metadata": {},
   "source": [
    "Ahora creamos el modelo y lo entrenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el modelo y le pasamos los datos de entrada y sus correspondientes etiquetas.\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X, y) #entrenamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac04a30",
   "metadata": {},
   "source": [
    "Veamos que tan bien separa los datos el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03413ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(-4, 5, 15)\n",
    "yy = np.linspace(-12, 2, 15)\n",
    "xy1, xy2 = np.meshgrid(xx, yy)\n",
    "Z = np.array([svc.decision_function([t])\n",
    "              for t in zip(xy1.flat, xy2.flat)]).reshape(xy1.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "estiloLineas = dict(levels = [-1.0, 0.0, 1.0],\n",
    "                  linestyles = ['dashed', 'solid', 'dashed'],\n",
    "                  colors = 'blue', linewidths=1)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"SVC entrenado a partir de los datos\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **estiloPuntos)\n",
    "ax.contour(xy1, xy2, Z, **estiloLineas)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882dd0d3",
   "metadata": {},
   "source": [
    "Veamos que tan bien funciona nuestro modelo para predecir nuevos puntos.\n",
    "\n",
    "Para esto generaremos puntos nuevos y usaremos el modelo *svc* entrenado para predecir a qué clase pertenecen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d040af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, _ = make_blobs(n_samples=100, centers=2, random_state=2, cluster_std=0.95)\n",
    "X2 = X2[50:]\n",
    "\n",
    "# Predecimos a que clase (etiqueta) pertenecen nuestros puntos utilizando el modelo entrenado\n",
    "y2 = svc.predict(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217324d5",
   "metadata": {},
   "source": [
    "Ahora graficaremos los datos nuevos sin clasificación y luego habiendo sido clasificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b645289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols = 2, figsize = (14,6))\n",
    "\n",
    "ax[0].set_xlabel(\"Feature 1\")\n",
    "ax[0].set_ylabel(\"Feature 2\")\n",
    "ax[0].set_title(\"Datos de entrada nuevos (y desconocidos)\")\n",
    "ax[0].scatter(X2[:, 0], X2[:, 1])\n",
    "ax[0].axis([-4, 4, -12, 2])\n",
    "\n",
    "ax[1].set_xlabel(\"Feature 1\")\n",
    "ax[1].set_ylabel(\"Feature 2\")\n",
    "ax[1].set_title(\"Datos nuevos clasificados\")\n",
    "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, **estiloPuntos)\n",
    "ax[1].contour(xy1, xy2, Z, **estiloLineas)\n",
    "ax[1].axis([-4, 4, -12, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072b541",
   "metadata": {},
   "source": [
    "### Ejemplo de Regresión\n",
    "\n",
    "Ahora vamosa generar un sencillo ejemplo de regresión lineal para clasificar datos continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generamos datos \n",
    "rng = np.random.RandomState(10)\n",
    "X = rng.randn(200, 2) #posición de los puntos en el espacio\n",
    "y = np.dot(X, [-2, 1]) + 1 * rng.randn(X.shape[0]) #etiquetas de los puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los puntos.\n",
    "plt.style.use(\"seaborn\")\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap='winter')\n",
    "\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "\n",
    "ax.axis([-3, 3, -4, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Posición de los puntos\")\n",
    "print(X[:10])\n",
    "print()\n",
    "print(\"Etiquetas\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25906fd",
   "metadata": {},
   "source": [
    "Cada color representa una etiqueta diferente para cada punto.\n",
    "\n",
    "Podríamos pensar también en que cada punto tiene una *altura* diferente y dicha altura se corresponde con la etiqueta. Esto lo podemos representar en un gráfico de tres dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841eaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = np.hstack([X, y[:, None]])\n",
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e3c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(datos[:,0], datos[:,1], datos[:,2],c=y, s=40, cmap='winter')\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_zlabel(\"Labels\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "\n",
    "# ax.view_init(-10, -120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4dcd6",
   "metadata": {},
   "source": [
    "#### Etiquetando datos\n",
    "\n",
    "A partir de analizar los datos en 3D podemos pensar que un plano ayudaría a separar los puntos. Una forma de hacer esto es entrenando un [Regresor Lineal](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9066472",
   "metadata": {},
   "source": [
    "Podemos proyectar los datos 3D en 2D con el plano obtenido luego de entrenar el regresor lineal con los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pts = ax.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap='winter', zorder=2)\n",
    "\n",
    "# compute and plot model color mesh\n",
    "xx, yy = np.meshgrid(np.linspace(-4, 4),np.linspace(-3, 3))\n",
    "Xfit = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "yfit = lr.predict(Xfit)\n",
    "zz = yfit.reshape(xx.shape)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada con el regresor lineal\")\n",
    "ax.pcolorfast([-4, 4], [-4, 4], zz, alpha=0.5, cmap='winter', norm=pts.norm, zorder=1)\n",
    "\n",
    "ax.axis([-3, 3, -4, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8483a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creamos nuevos datos\n",
    "X2 = rng.randn(100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtenemos las etiquetas para estos nuevos datos a través del modelo entrenado\n",
    "\n",
    "y2 = lr.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los nuevos datos.\n",
    "plt.style.use(\"seaborn\")\n",
    "fig, ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].set_xlabel(\"Feature 1\")\n",
    "ax[0].set_ylabel(\"Feature 2\")\n",
    "ax[0].set_title(\"Datos desconocidos\")\n",
    "ax[0].axis([-3, 3, -4, 4])\n",
    "ax[0].scatter(X2[:, 0], X2[:, 1])\n",
    "\n",
    "ax[1].set_xlabel(\"Feature 1\")\n",
    "ax[1].set_ylabel(\"Feature 2\")\n",
    "ax[1].set_title(\"Etiquetas para los nuevos datos usando el Regresor Lineal\")\n",
    "ax[1].axis([-3, 3, -4, 4])\n",
    "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=40, cmap='winter')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82357152",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "Hemos visto dos sencillos modelos de aprendizaje supervisado. Los mismos aprenden de datos etiquetados y una vez entrenados, sirven para etiquetar datos nuevos.\n",
    "\n",
    "En el caso del aprendizaje no supervisado, el modelo *aprende* sin ninguna referencia a una etiqueta.\n",
    "\n",
    "### Ejemplo de Clustering\n",
    "\n",
    "Un método muy conocido de aprendizaje no supervisado es *Clustering*, en donde los datos son asignados a un número *n* de grupos discretos.\n",
    "\n",
    "Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# creamos 100 puntos separados con cuatro centros. Sólo nos quedamos con las posiciones.\n",
    "X, _ = make_blobs(n_samples = 100, centers = 4, random_state = 20, cluster_std=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada\")\n",
    "ax.scatter(X[:, 0], X[:, 1])\n",
    "ax.axis([-15, 12, -5, 13])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9af1a",
   "metadata": {},
   "source": [
    "#### Kmeans\n",
    "\n",
    "Utilizaremos el algoritmo de Kmeans para separar en grupos los datos de entrada que hemos generado. Sikit-learn provee su propio método dado por [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters = 4, random_state=0) #le decimos que queremos que nos separe en 4 grupos\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debabcf5",
   "metadata": {},
   "source": [
    "Utilizamos el modelo entrenado para obtener los grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fa6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# plot the data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "estiloPuntos = dict(cmap='magma_r', s=45)\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos de entrada agrupados con Kmeans\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, **estiloPuntos)\n",
    "ax.axis([-15, 12, -5, 13])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d351c7",
   "metadata": {},
   "source": [
    "**Importante**: Debemos tener en claro que los grupos se obtuvieron a partir del algortimo, es decir, que *Kmeans()* nos permitió agrupar los datos y luego los etiquetamos, esto puede verse gracias a los colores diferentes que toman los puntos, donde cada color representa un grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b6651",
   "metadata": {},
   "source": [
    "### Reduciendo la dimensiones de mis datos\n",
    "\n",
    "En muchos casos, los datos son 𝑁-dimensionales, con 𝑁>3. Podría ser útil reducir la dimensión de nuestros datos, para analizarlos, para procesarlos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "# make data\n",
    "X, y = make_swiss_roll(200, noise=0.5, random_state=42)\n",
    "X = X[:, [0, 2]]\n",
    "\n",
    "# visualize data\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Datos originales\")\n",
    "ax.scatter(X[:, 0], X[:, 1], s=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176d4fe4",
   "metadata": {},
   "source": [
    "#### Algoritmos del tipo *Manifold*\n",
    "\n",
    "Podemos usar un algoritmo conocido como [Isometric Mapping](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py) para reducir la dimensión de nuestros datos. En escencia lo que intenta hacer el algoritmo es extraer información para representar los datos en dimensiones bajas, y al mismo tiempo, preservar las características relevantes del conjunto de datos, el cual se supone posee una estructura compleja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "isomap = Isomap(n_neighbors=8, n_components=1)\n",
    "y_Obtenidos = isomap.fit_transform(X).ravel()\n",
    "\n",
    "# visualize data\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Feature 1\")\n",
    "ax.set_ylabel(\"Feature 2\")\n",
    "ax.set_title(\"Variación de datos aprendido por Isomap\")\n",
    "pts = ax.scatter(X[:, 0], X[:, 1], c=y_Obtenidos, cmap='winter', s=30)\n",
    "cb = fig.colorbar(pts, ax=ax)\n",
    "cb.set_ticks([])\n",
    "cb.set_label('Variación latente', color='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d3b1d",
   "metadata": {},
   "source": [
    "## Introducción a *Scikit-Learn*\n",
    "\n",
    "Sabemos que el ML trata de entrenar modelos a partir de datos para hacer algo con ellos.\n",
    "\n",
    "Ahora bien, ¿qué estructura deben de tener los datos para poder entrenar algoritmos?\n",
    "\n",
    "**Datos como tablas**\n",
    "\n",
    "La forma básica es trabajar los datos como tablas.\n",
    "\n",
    "Las columnas representan las características y las filas las observaciones.\n",
    "\n",
    "Veamos un ejemplo con un set muy conocido, el cual se llama *Iris dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542250fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d9de2",
   "metadata": {},
   "source": [
    "Si tomamos a la columna *species* como el *vector de blancos* entonces podemos ver que nuestros datos poseen una matríz de características con un tamaño de $150 x 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6a9d6",
   "metadata": {},
   "source": [
    "#### Pasos básicos para la implementación de un modelo.\n",
    "\n",
    "1. Elegir un modelo adecuado al problema que queremos resolver/analizar.\n",
    "2. Elegir los hiperparámetros del modelo instanciando esta clase con los valores deseados\n",
    "3. Organizar los datos en una matriz de características y un vector blanco/target de la forma vista anteriormente.\n",
    "4. Entrenar el modelo invocando al método fit().\n",
    "5. Aplicar el modelo a nuevos datos:\n",
    "    - Para aprendizaje supervisado, a menudo predecimos etiquetas para datos desconocidos usando el método de prediction().\n",
    "    - Para aprendizaje no supervisado, a menudo transformamos o inferimos propiedades de los datos utilizando el método transform() o predict().\n",
    "\n",
    "Veamos un ejemplo…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5a6dc",
   "metadata": {},
   "source": [
    "### Clasificando dígitos escritos a mano\n",
    "\n",
    "Vamos a intentar clasificar números que han sido escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28893ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5006cb7f",
   "metadata": {},
   "source": [
    "Podemos ver tenemos 1797 dígitos de $8x8$.\n",
    "\n",
    "Vamos a graficar algunos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50022a5d",
   "metadata": {},
   "source": [
    "#### Construyendo los datos en *matriz de características* y *target vector*\n",
    "\n",
    "Primeramente debemos arreglar los datos de tal manera de poder entrenar modelos con Scikit-learn. Para esto necesitamos una tabla de dos dimensiones del tipo [$n_samples$ x $n_features$].\n",
    "\n",
    "Debemos notar que cada dígito es una matriz de 8x8 pixéles. Por lo tanto, podemos formar vectores filas de 64 píxeles y acomodarlos de tal manera de que formen una matriz de *1797 x 64*.\n",
    "\n",
    "Además también necesitamos un *target vector*. Estos datos los podemos obtener directamente de *digits = load_digits()*, veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71885d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data #Matriz de Características\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd86cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d92888",
   "metadata": {},
   "source": [
    "Ya tenemos los datos en la forma necesaria para ser utilizados con Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b9a06e",
   "metadata": {},
   "source": [
    "#### Separando en datos de entrenamiento y de testeo\n",
    "\n",
    "Antes que nada, es **de suma importancia** separar los datos en un set de entrenamiento y en otro de testeo. Volveremos sobre esto más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d0d94",
   "metadata": {},
   "source": [
    "#### Visualizando nuestros datos de entrenamiento.\n",
    "\n",
    "Esta claro que tenemos datos que son difíciles de interpretar debido a que se encuentran en un espacio de 64 dimensiones. Por lo tanto, aplicaremos la estrategia de *reducción de dimensionalidad*, es decir, una estrategia de *aprendizaje no supervisado* para intentar analizar los datos que tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec91ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "isomap = Isomap(n_components=2)\n",
    "isomap.fit(Xtrain)\n",
    "datosProyectados = isomap.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "datosProyectados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(datosProyectados[:, 0], datosProyectados[:, 1], c=ytrain, edgecolor='none', alpha=0.4,\n",
    "            cmap=plt.cm.get_cmap('jet', 10))\n",
    "\n",
    "plt.title(\"Isomap de los dígitos - Reducido de 64 a 2 dimensiones\")\n",
    "plt.colorbar(label='label de los dígitos', ticks=range(10))\n",
    "plt.clim(-0.5, 9.5);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54bb00",
   "metadata": {},
   "source": [
    "La gráfica de isomap nos da una buena idea de que tan bien los números escritos a mano se encuentran separados en el espacio de 64 dimensiones. Por ejemplo, los ceros y los unos pareciera ser que pueden separarse facilmente, al igual que los dígitos cuatro. Esto tiene sentido, por ejemplo, los ceros poseen un hueco en el medio, mientras que los unos son un *palo* en el centro de la imágen.\n",
    "\n",
    "En el caso de los dos y los siete, parecen solaparse. Una vez más, intuitivamente esto tiene sentido, un dos y un siete tienen cierta similitud a la hora de dibujarse.\n",
    "\n",
    "Podríamos decir que los datos están más o menos bien separados, ¿o no? Intentemos clasificar los números a partir de los datos reducidos en dimensiones.\n",
    "\n",
    "Utilizaremos el clasificador llamado [sklearn.naive_bayes.GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d98178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # 1. elegimos el clasificador\n",
    "model = GaussianNB()                       # 2. y 3. instanciamos el modelo\n",
    "model.fit(Xtrain, ytrain)                  # 4. entrenamos el modelo con el método fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9675adae",
   "metadata": {},
   "source": [
    "Debemos notar que hemos entrenado el modelo con los datos de entrenamiento *Xtrain* y las etiquetas de entrenamiento, es decir, *ytrain*.\n",
    "\n",
    "Ahora vamos a clasificar los datos de *Xtest* para etiquetas datos **desconocidos** por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yModelo = model.predict(Xtest)             # 5. clasificamos sobre los datos de testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60723d",
   "metadata": {},
   "source": [
    "Ahora vamos a medir la *performance* del modelo. Para esto vamos a comparar las etiquetas de testeo *ytest* versus las obtenidas *yModelo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "round(accuracy_score(ytest, yModelo),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733de1df",
   "metadata": {},
   "source": [
    "Un 83% de precisión en la clasificación no esta nada mal para un procedimiento sumamente sencillo. Hemos entrenado un modelo y clasificado nuevos datos en muy pocas líneas de código.\n",
    "\n",
    "Podemos utilizar una matriz de confusión para ver rápidamente la performance de nuestro clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e33ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(ytest, yModelo)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('Valores clasificados')\n",
    "plt.ylabel('Valores verdaderos');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f16d0",
   "metadata": {},
   "source": [
    "Analicemos qué números fueron los que se clasificaron incorrectamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "imagenesTest = Xtest.reshape(-1, 8, 8)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(imagenesTest[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(yModelo[i]),\n",
    "            transform=ax.transAxes, color='green' if (ytest[i] == yModelo[i]) else 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53169fa0",
   "metadata": {},
   "source": [
    "# <center> <span style='color:#3c3b5f'>FIN</span></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pda]",
   "language": "python",
   "name": "conda-env-pda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
